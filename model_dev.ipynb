{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alike-hughes",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import logging\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import dataset\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "from opts import parse_opts\n",
    "from utils import *\n",
    "from cfg import parse_cfg\n",
    "from region_loss import RegionLoss\n",
    "\n",
    "from model import YOWO, get_fine_tuning_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "portuguese-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "class options:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.dataset = 'ucf101-24' \n",
    "        self.data_cfg = 'cfg/ucf24.data' \n",
    "        self.cfg_file = 'cfg/ucf24.cfg' \n",
    "        self.n_classes = 24 \n",
    "        self.backbone_3d = 'resnext101' \n",
    "        self.backbone_3d_weights = 'weights/resnext-101-kinetics.pth' \n",
    "        self.backbone_2d = 'darknet' \n",
    "        self.backbone_2d_weights = 'weights/yolo.weights' \n",
    "        self.resume_path = 'backup'\n",
    "        self.freeze_backbone_2d = False\n",
    "        self.freeze_backbone_3d = False\n",
    "\n",
    "opt = options()\n",
    "# which dataset to use\n",
    "dataset_use   = opt.dataset\n",
    "assert dataset_use == 'ucf101-24' or dataset_use == 'jhmdb-21', 'invalid dataset'\n",
    "# path for dataset of training and validation\n",
    "datacfg       = opt.data_cfg\n",
    "# path for cfg file\n",
    "cfgfile       = opt.cfg_file\n",
    "\n",
    "data_options  = read_data_cfg(datacfg)\n",
    "net_options   = parse_cfg(cfgfile)[0]\n",
    "\n",
    "# obtain list for training and testing\n",
    "basepath      = data_options['base']\n",
    "trainlist     = data_options['train']\n",
    "testlist      = data_options['valid']\n",
    "backupdir     = data_options['backup']\n",
    "# number of training samples\n",
    "nsamples      = file_lines(trainlist)\n",
    "gpus          = data_options['gpus']  # e.g. 0,1,2,3\n",
    "ngpus         = len(gpus.split(','))\n",
    "num_workers   = int(data_options['num_workers'])\n",
    "\n",
    "batch_size    = int(net_options['batch'])\n",
    "clip_duration = int(net_options['clip_duration'])\n",
    "max_batches   = int(net_options['max_batches'])\n",
    "learning_rate = float(net_options['learning_rate'])\n",
    "momentum      = float(net_options['momentum'])\n",
    "decay         = float(net_options['decay'])\n",
    "steps         = [float(step) for step in net_options['steps'].split(',')]\n",
    "scales        = [float(scale) for scale in net_options['scales'].split(',')]\n",
    "\n",
    "# loss parameters\n",
    "loss_options               = parse_cfg(cfgfile)[1]\n",
    "region_loss                = RegionLoss()\n",
    "anchors                    = loss_options['anchors'].split(',')\n",
    "region_loss.anchors        = [float(i) for i in anchors]\n",
    "region_loss.num_classes    = int(loss_options['classes'])\n",
    "region_loss.num_anchors    = int(loss_options['num'])\n",
    "region_loss.anchor_step    = len(region_loss.anchors)//region_loss.num_anchors\n",
    "region_loss.object_scale   = float(loss_options['object_scale'])\n",
    "region_loss.noobject_scale = float(loss_options['noobject_scale'])\n",
    "region_loss.class_scale    = float(loss_options['class_scale'])\n",
    "region_loss.coord_scale    = float(loss_options['coord_scale'])\n",
    "region_loss.batch          = batch_size\n",
    "        \n",
    "#Train parameters\n",
    "max_epochs    = max_batches*batch_size//nsamples+1\n",
    "use_cuda      = True\n",
    "seed          = int(time.time())\n",
    "eps           = 1e-5\n",
    "best_fscore   = 0 # initialize best fscore\n",
    "\n",
    "# Test parameters\n",
    "nms_thresh    = 0.4\n",
    "iou_thresh    = 0.5\n",
    "\n",
    "if not os.path.exists(backupdir):\n",
    "    os.mkdir(backupdir)\n",
    "    \n",
    "torch.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = gpus\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Create model\n",
    "model = YOWO(opt)\n",
    "\n",
    "model       = model.cuda()\n",
    "model       = nn.DataParallel(model, device_ids=None) # in multi-gpu case\n",
    "model.seen  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "photographic-bhutan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): YOWO(\n",
      "    (backbone_2d): Darknet(\n",
      "      (models): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (leaky1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        )\n",
      "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (2): Sequential(\n",
      "          (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (leaky2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        )\n",
      "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (4): Sequential(\n",
      "          (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (leaky3): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        )\n",
      "        (5): Sequential(\n",
      "          (conv4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (leaky4): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        )\n",
      "        (6): Sequential(\n",
      "          (conv5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (leaky5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        )\n",
      "        (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (8): Sequential(\n",
      "          (conv6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (leaky6): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        )\n",
      "        (9): Sequential(\n",
      "          (conv7): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (leaky7): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        )\n",
      "        (10): Sequential(\n",
      "          (conv8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (leaky8): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        )\n",
      "        (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (12): Sequential(\n",
      "          (conv9): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (leaky9): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        )\n",
      "        (13): Sequential(\n",
      "          (conv10): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (leaky10): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        )\n",
      "        (14): Sequential(\n",
      "          (conv11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn11): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (leaky11): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        )\n",
      "        (15): Sequential(\n",
      "          (conv12): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (leaky12): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        )\n",
      "        (16): Sequential(\n",
      "          (conv13): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (leaky13): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        )\n",
      "        (17): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (18): Sequential(\n",
      "          (conv14): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn14): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (leaky14): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        )\n",
      "        (19): Sequential(\n",
      "          (conv15): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (leaky15): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        )\n",
      "        (20): Sequential(\n",
      "          (conv16): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn16): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (leaky16): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        )\n",
      "        (21): Sequential(\n",
      "          (conv17): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (leaky17): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        )\n",
      "        (22): Sequential(\n",
      "          (conv18): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn18): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (leaky18): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        )\n",
      "        (23): Sequential(\n",
      "          (conv19): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn19): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (leaky19): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        )\n",
      "        (24): Sequential(\n",
      "          (conv20): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn20): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (leaky20): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        )\n",
      "        (25): EmptyModule()\n",
      "        (26): Sequential(\n",
      "          (conv21): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn21): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (leaky21): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        )\n",
      "        (27): Reorg()\n",
      "        (28): EmptyModule()\n",
      "        (29): Sequential(\n",
      "          (conv22): Conv2d(1280, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn22): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (leaky22): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        )\n",
      "        (30): Sequential(\n",
      "          (conv23): Conv2d(1024, 425, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (31): RegionLoss()\n",
      "      )\n",
      "      (loss): RegionLoss()\n",
      "    )\n",
      "    (backbone_3d): ResNeXt(\n",
      "      (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
      "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
      "            (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
      "            (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (6): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (7): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (8): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (9): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (10): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (11): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (12): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (13): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (14): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (15): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (16): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (17): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (18): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (19): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (20): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (21): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (22): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(1024, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
      "            (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ResNeXtBottleneck(\n",
      "          (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
      "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (cfam): CFAMBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(2473, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv_bn_relu2): Sequential(\n",
      "        (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (sc): CAM_Module(\n",
      "        (softmax): Softmax(dim=-1)\n",
      "      )\n",
      "      (conv_bn_relu3): Sequential(\n",
      "        (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv_out): Sequential(\n",
      "        (0): Dropout2d(p=0.1, inplace=False)\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (conv_final): Conv2d(1024, 145, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "closed-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = get_fine_tuning_parameters(model, opt)\n",
    "optimizer = optim.SGD(parameters, lr=learning_rate/batch_size, momentum=momentum, dampening=0, weight_decay=decay*batch_size)\n",
    "\n",
    "kwargs = {'num_workers': num_workers, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "optical-contents",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================\n"
     ]
    }
   ],
   "source": [
    "if opt.resume_path:\n",
    "    print(\"===================================================================\")\n",
    "    if '.pth' in opt.resume_path:\n",
    "        chkpt = opt.resume_path\n",
    "    else:\n",
    "        chkpt_core = 'yowo_' + opt.dataset + '_' + str(clip_duration) + 'f'\n",
    "        chkpt = sorted([c for c in os.listdir(opt.resume_path) if chkpt_core in c and 'checkpoint.pth' in c])\n",
    "        if chkpt:\n",
    "            chkpt = os.path.join(opt.resume_path,chkpt[-1])\n",
    "    if chkpt:\n",
    "        print('loading checkpoint {}'.format(chkpt))\n",
    "        checkpoint = torch.load(chkpt)\n",
    "        opt.begin_epoch = checkpoint['epoch'] + 1\n",
    "        best_fscore = checkpoint['fscore']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        model.seen = checkpoint['epoch'] * nsamples\n",
    "        print(\"Loaded model fscore: \", checkpoint['fscore'])\n",
    "        print(\"===================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "arbitrary-ready",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_loss.seen  = model.seen\n",
    "processed_batches = model.seen//batch_size\n",
    "\n",
    "init_width        = int(net_options['width'])\n",
    "init_height       = int(net_options['height'])\n",
    "init_epoch        = model.seen//nsamples \n",
    "\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, batch):\n",
    "    lr = learning_rate\n",
    "    for i in range(len(steps)):\n",
    "        scale = scales[i] if i < len(scales) else 1\n",
    "        if batch >= steps[i]:\n",
    "            lr = lr * scale\n",
    "            if batch == steps[i]:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr/batch_size\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "photographic-assets",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, target = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "streaming-operation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 3, 16, 224, 224])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "prerequisite-banks",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import RandomSampler\n",
    "n_sample_from = 15\n",
    "def train(epoch):\n",
    "    global processed_batches\n",
    "    t0 = time.time()\n",
    "    cur_model = model.module\n",
    "    region_loss.l_x.reset()\n",
    "    region_loss.l_y.reset()\n",
    "    region_loss.l_w.reset()\n",
    "    region_loss.l_h.reset()\n",
    "    region_loss.l_conf.reset()\n",
    "    region_loss.l_cls.reset()\n",
    "    region_loss.l_total.reset()\n",
    "    train_dataset = dataset.listDataset(basepath, trainlist, dataset_use=dataset_use, shape=(init_width, init_height),\n",
    "                                        shuffle=True,\n",
    "                                        transform=transforms.Compose([\n",
    "                                            transforms.ToTensor(),\n",
    "                                        ]), \n",
    "                                        train=True, \n",
    "                                        seen=cur_model.seen,\n",
    "                                        batch_size=batch_size,\n",
    "                                        clip_duration=clip_duration,\n",
    "                                        num_workers=num_workers)\n",
    "    rs = RandomSampler(train_dataset,replacement=True, num_samples=int(len(train_dataset)/n_sample_from))\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,sampler=rs,\n",
    "                                               batch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "    lr = adjust_learning_rate(optimizer, processed_batches)\n",
    "    total_batch = len(train_loader)\n",
    "    logging('training at epoch %d, lr %f' % (epoch, lr))\n",
    "    logging('total # of batches %d' % (total_batch))\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        adjust_learning_rate(optimizer, processed_batches)\n",
    "        processed_batches = processed_batches + 1\n",
    "\n",
    "        if use_cuda:\n",
    "            data = data.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        region_loss.seen = region_loss.seen + data.data.size(0)\n",
    "        loss = region_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx%20 == 0:\n",
    "            logging(f'===== epoch: {epoch}, batch: {batch_idx+1}/{total_batch}, lr:{lr}, loss: {loss.item()} =====')\n",
    "        \n",
    "        # save result every 1000 batches\n",
    "        if processed_batches % 500 == 0: # From time to time, reset averagemeters to see improvements\n",
    "            region_loss.l_x.reset()\n",
    "            region_loss.l_y.reset()\n",
    "            region_loss.l_w.reset()\n",
    "            region_loss.l_h.reset()\n",
    "            region_loss.l_conf.reset()\n",
    "            region_loss.l_cls.reset()\n",
    "            region_loss.l_total.reset()\n",
    "\n",
    "    t1 = time.time()\n",
    "    logging('trained with %f samples/s' % (len(train_loader.dataset)/(t1-t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "floral-blend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-26 21:19:06 training at epoch 0, lr 0.000100\n",
      "2021-03-26 21:19:06 total # of batches 1877\n",
      "2021-03-26 21:19:25 ===== epoch: 0, batch: 1/1877, lr:0.0001, loss: 17.530460357666016 =====\n",
      "2021-03-26 21:19:57 ===== epoch: 0, batch: 21/1877, lr:0.0001, loss: 25.349815368652344 =====\n",
      "2021-03-26 21:20:29 ===== epoch: 0, batch: 41/1877, lr:0.0001, loss: 24.264196395874023 =====\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d713a55a44c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-463b14629ee7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregion_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/YW/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/YW/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/YW/lib/python3.9/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    108\u001b[0m                         \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             F.sgd(params_with_grad,\n\u001b[0m\u001b[1;32m    111\u001b[0m                   \u001b[0md_p_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                   \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/YW/lib/python3.9/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "arabic-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    def truths_length(truths):\n",
    "        for i in range(50):\n",
    "            if truths[i][1] == 0:\n",
    "                return i\n",
    "    test_dataset = dataset.listDataset(basepath, testlist, dataset_use=dataset_use, shape=(init_width, init_height),\n",
    "                                       shuffle=False,\n",
    "                                       transform=transforms.Compose([\n",
    "                                           transforms.ToTensor()\n",
    "                                       ]), train=False)\n",
    "    test_rs = RandomSampler(test_dataset, replacement=True, num_samples=int(len(test_dataset)/n_sample_from))\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, sampler=test_rs,\n",
    "                                              batch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "    num_classes = region_loss.num_classes\n",
    "    anchors     = region_loss.anchors\n",
    "    num_anchors = region_loss.num_anchors\n",
    "    conf_thresh_valid = 0.005\n",
    "    total       = 0.0\n",
    "    proposals   = 0.0\n",
    "    correct     = 0.0\n",
    "    fscore = 0.0\n",
    "\n",
    "    correct_classification = 0.0\n",
    "    total_detected = 0.0\n",
    "\n",
    "    nbatch      = len(test_loader) # file_lines(testlist) // batch_size\n",
    "\n",
    "    logging('validation at epoch %d' % (epoch))\n",
    "    model.eval()\n",
    "\n",
    "    for batch_idx, (frame_idx, data, target) in enumerate(test_loader):\n",
    "        if use_cuda:\n",
    "            data = data.cuda()\n",
    "        with torch.no_grad():\n",
    "            output = model(data).data\n",
    "            all_boxes = get_region_boxes(output, conf_thresh_valid, num_classes, anchors, num_anchors, 0, 1)\n",
    "            for i in range(output.size(0)):\n",
    "                boxes = all_boxes[i]\n",
    "                boxes = nms(boxes, nms_thresh)\n",
    "                if dataset_use == 'ucf101-24':\n",
    "                    detection_path = os.path.join('ucf_detections', 'detections_'+str(epoch), frame_idx[i])\n",
    "                    current_dir = os.path.join('ucf_detections', 'detections_'+str(epoch))\n",
    "                    if not os.path.exists('ucf_detections'):\n",
    "                        os.mkdir('ucf_detections')\n",
    "                    if not os.path.exists(current_dir):\n",
    "                        os.mkdir(current_dir)\n",
    "                else:\n",
    "                    detection_path = os.path.join('jhmdb_detections', 'detections_'+str(epoch), frame_idx[i])\n",
    "                    current_dir = os.path.join('jhmdb_detections', 'detections_'+str(epoch))\n",
    "                    if not os.path.exists('jhmdb_detections'):\n",
    "                        os.mkdir('jhmdb_detections')\n",
    "                    if not os.path.exists(current_dir):\n",
    "                        os.mkdir(current_dir)\n",
    "\n",
    "                with open(detection_path, 'w+') as f_detect:\n",
    "                    for box in boxes:\n",
    "                        x1 = round(float(box[0]-box[2]/2.0) * 320.0)\n",
    "                        y1 = round(float(box[1]-box[3]/2.0) * 240.0)\n",
    "                        x2 = round(float(box[0]+box[2]/2.0) * 320.0)\n",
    "                        y2 = round(float(box[1]+box[3]/2.0) * 240.0)\n",
    "\n",
    "                        det_conf = float(box[4])\n",
    "                        for j in range((len(box)-5)//2):\n",
    "                            cls_conf = float(box[5+2*j].item())\n",
    "\n",
    "                            if type(box[6+2*j]) == torch.Tensor:\n",
    "                                cls_id = int(box[6+2*j].item())\n",
    "                            else:\n",
    "                                cls_id = int(box[6+2*j])\n",
    "                            prob = det_conf * cls_conf\n",
    "\n",
    "                            f_detect.write(str(int(box[6])+1) + ' ' + str(prob) + ' ' + str(x1) + ' ' + str(y1) + ' ' + str(x2) + ' ' + str(y2) + '\\n')\n",
    "                truths = target[i].view(-1, 5)\n",
    "                num_gts = truths_length(truths)\n",
    "        \n",
    "                total = total + num_gts\n",
    "    \n",
    "                for i in range(len(boxes)):\n",
    "                    if boxes[i][4] > 0.25:\n",
    "                        proposals = proposals+1\n",
    "\n",
    "                for i in range(num_gts):\n",
    "                    box_gt = [truths[i][1], truths[i][2], truths[i][3], truths[i][4], 1.0, 1.0, truths[i][0]]\n",
    "                    best_iou = 0\n",
    "                    best_j = -1\n",
    "                    for j in range(len(boxes)):\n",
    "                        iou = bbox_iou(box_gt, boxes[j], x1y1x2y2=False)\n",
    "                        if iou > best_iou:\n",
    "                            best_j = j\n",
    "                            best_iou = iou\n",
    "\n",
    "                    if best_iou > iou_thresh:\n",
    "                        total_detected += 1\n",
    "                        if int(boxes[best_j][6]) == box_gt[6]:\n",
    "                            correct_classification += 1\n",
    "\n",
    "                    if best_iou > iou_thresh and int(boxes[best_j][6]) == box_gt[6]:\n",
    "                        correct = correct+1\n",
    "\n",
    "            precision = 1.0*correct/(proposals+eps)\n",
    "            recall = 1.0*correct/(total+eps)\n",
    "            fscore = 2.0*precision*recall/(precision+recall+eps)\n",
    "            logging(\"[%d/%d] precision: %f, recall: %f, fscore: %f\" % (batch_idx, nbatch, precision, recall, fscore))\n",
    "\n",
    "    classification_accuracy = 1.0 * correct_classification / (total_detected + eps)\n",
    "    locolization_recall = 1.0 * total_detected / (total + eps)\n",
    "\n",
    "    logging(\"Classification accuracy: %.3f\" % classification_accuracy)\n",
    "    logging(\"Localization recall: %.3f\" % locolization_recall)\n",
    "\n",
    "    return fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "tight-bathroom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-26 21:23:35 validation at epoch 0\n",
      "2021-03-26 21:23:51 [0/765] precision: 0.999999, recall: 0.666666, fscore: 0.799995\n",
      "2021-03-26 21:23:54 [1/765] precision: 1.049999, recall: 0.724138, fscore: 0.857138\n",
      "2021-03-26 21:23:56 [2/765] precision: 1.000000, recall: 0.604651, fscore: 0.753618\n",
      "2021-03-26 21:23:58 [3/765] precision: 1.000000, recall: 0.561403, fscore: 0.719096\n",
      "2021-03-26 21:24:01 [4/765] precision: 1.162162, recall: 0.589041, fscore: 0.781814\n",
      "2021-03-26 21:24:04 [5/765] precision: 1.204545, recall: 0.602273, fscore: 0.803026\n",
      "2021-03-26 21:24:07 [6/765] precision: 1.234042, recall: 0.568627, fscore: 0.778519\n",
      "2021-03-26 21:24:09 [7/765] precision: 1.203703, recall: 0.570175, fscore: 0.773805\n",
      "2021-03-26 21:24:12 [8/765] precision: 1.228070, recall: 0.551181, fscore: 0.760865\n",
      "2021-03-26 21:24:14 [9/765] precision: 1.311475, recall: 0.563380, fscore: 0.788173\n",
      "2021-03-26 21:24:17 [10/765] precision: 1.343283, recall: 0.566038, fscore: 0.796456\n",
      "2021-03-26 21:24:19 [11/765] precision: 1.382353, recall: 0.549708, fscore: 0.786607\n",
      "2021-03-26 21:24:22 [12/765] precision: 1.430555, recall: 0.556757, fscore: 0.801552\n",
      "2021-03-26 21:24:25 [13/765] precision: 1.472973, recall: 0.545000, fscore: 0.795616\n",
      "2021-03-26 21:24:27 [14/765] precision: 1.487179, recall: 0.544601, fscore: 0.797247\n",
      "2021-03-26 21:24:29 [15/765] precision: 1.463414, recall: 0.533333, fscore: 0.781755\n",
      "2021-03-26 21:24:31 [16/765] precision: 1.453488, recall: 0.525210, fscore: 0.771601\n",
      "2021-03-26 21:24:34 [17/765] precision: 1.431579, recall: 0.535433, fscore: 0.779366\n",
      "2021-03-26 21:24:36 [18/765] precision: 1.425742, recall: 0.537313, fscore: 0.780484\n",
      "2021-03-26 21:24:37 [19/765] precision: 1.388889, recall: 0.530035, fscore: 0.767259\n",
      "2021-03-26 21:24:38 [20/765] precision: 1.382609, recall: 0.526490, fscore: 0.762586\n",
      "2021-03-26 21:24:39 [21/765] precision: 1.349593, recall: 0.523659, fscore: 0.754541\n",
      "2021-03-26 21:24:41 [22/765] precision: 1.301470, recall: 0.531532, fscore: 0.754793\n",
      "2021-03-26 21:24:41 [23/765] precision: 1.328467, recall: 0.526012, fscore: 0.753619\n",
      "2021-03-26 21:24:43 [24/765] precision: 1.340425, recall: 0.526462, fscore: 0.755996\n",
      "2021-03-26 21:24:44 [25/765] precision: 1.313333, recall: 0.525333, fscore: 0.750472\n",
      "2021-03-26 21:24:45 [26/765] precision: 1.301282, recall: 0.517857, fscore: 0.740872\n",
      "2021-03-26 21:24:46 [27/765] precision: 1.331210, recall: 0.517327, fscore: 0.745094\n",
      "2021-03-26 21:24:47 [28/765] precision: 1.358025, recall: 0.525060, fscore: 0.757311\n",
      "2021-03-26 21:24:48 [29/765] precision: 1.355422, recall: 0.519630, fscore: 0.751248\n",
      "2021-03-26 21:24:49 [30/765] precision: 1.358823, recall: 0.516779, fscore: 0.748780\n",
      "2021-03-26 21:24:50 [31/765] precision: 1.356322, recall: 0.513043, fscore: 0.744475\n",
      "2021-03-26 21:24:52 [32/765] precision: 1.366667, recall: 0.517895, fscore: 0.751141\n",
      "2021-03-26 21:24:53 [33/765] precision: 1.352941, recall: 0.516327, fscore: 0.747411\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-9ef624c49652>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-c2cd62455faf>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_boxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnms_thresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdataset_use\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ucf101-24'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0mdetection_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ucf_detections'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'detections_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/ssd002/home/ylwu/YOWO/utils.py\u001b[0m in \u001b[0;36mnms\u001b[0;34m(boxes, nms_thresh)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mbox_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msortIds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_iou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1y1x2y2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mnms_thresh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                     \u001b[0;31m#print(box_i, box_j, bbox_iou(box_i, box_j, x1y1x2y2=False))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                     \u001b[0mbox_j\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/ssd002/home/ylwu/YOWO/utils.py\u001b[0m in \u001b[0;36mbbox_iou\u001b[0;34m(box1, box2, x1y1x2y2)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0muh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mcarea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcw\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mch\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
